{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e5f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd02b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87dcb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor((1, 2, -1))\n",
    "b = torch.tensor((3, 0, 4))\n",
    "torch.maximum(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef3e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_thr(x, alpha):\n",
    "    n = x.shape[0]\n",
    "    S = torch.maximum(x-alpha, \n",
    "        torch.zeros(n,device='cuda:0'))*torch.sign(x)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e1d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTA(beta, X, y, lamb, L, eta , tol = 1e-04, max_iter = 5000, dtype = torch.float32):\n",
    "    if(dtype == torch.float32):\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    else:\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    dbeta = torch.Tensor(beta).to(device)\n",
    "    dX = torch.Tensor(X).to(device)\n",
    "    dy = torch.Tensor(y).to(device)\n",
    "    t = torch.ones(1,dtype=dtype, device=device)\n",
    "    crit = np.zeros(max_iter)\n",
    "    dbeta_p = torch.Tensor(beta).to(device)\n",
    "    dbeta_prev = torch.Tensor(beta).to(device)\n",
    "    L_prev = L\n",
    "    for k in range(max_iter):\n",
    "        dymXbp = dy-torch.matmul(dX,dbeta_p)\n",
    "        drbp = torch.dot(dymXbp, dymXbp)\n",
    "        dXTrbp = torch.matmul(torch.t(dX),dymXbp)\n",
    "\n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            L_cur = L_prev*(eta**i_k)\n",
    "            dbstar = dbeta_p + dXTrbp/L_cur\n",
    "            dbeta = soft_thr(dbstar, lamb/L_cur)\n",
    "            diff_beta = dbeta - dbeta_p\n",
    "            RHS_1st = torch.dot(diff_beta,diff_beta)\n",
    "            RHS_2nd = torch.dot(diff_beta,dXTrbp)\n",
    "            RHS = L_cur*RHS_1st-2.0*RHS_2nd\n",
    "            dymXb = dy-torch.matmul(dX,dbeta)\n",
    "            LHS = torch.dot(dymXb,dymXb)-drbp\n",
    "            cond = (LHS>RHS)\n",
    "        L_prev = L_cur\n",
    "        tnext = (1.0+torch.sqrt(1+4*t**2))/2.0\n",
    "        diff_beta = dbeta-dbeta_prev\n",
    "        t1 = (t-1.0)/tnext\n",
    "        dbeta_p = dbeta+t1*diff_beta\n",
    "        crit[k] = torch.norm(diff_beta)\n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "        t = tnext\n",
    "        dbeta_prev = dbeta\n",
    "    out = dbeta.to('cpu')\n",
    "    return out.numpy(), crit, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7219e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 1\n",
    "comp_time_torch = np.zeros((niter,2))\n",
    "\n",
    "n = 100; p = 200\n",
    "for i in range(niter):\n",
    "\n",
    "    xmat = np.random.normal(size = (n, p)).astype(\"float64\")\n",
    "    beta = np.zeros(p)\n",
    "    beta[:int(0.05*p)] = 1.0\n",
    "    y = np.dot(xmat, beta) + np.random.normal(size = n)\n",
    "    lamb = np.float64(np.sqrt(2 * np.log(p) / n) )\n",
    "    L = np.float64(10)\n",
    "    eta = np.float64(2)\n",
    "    tol = np.float64(1e-04)\n",
    "\n",
    "    beta_sol = np.zeros(p, dtype = \"float64\")\n",
    "\n",
    "    t1 = time.time()\n",
    "    res = FISTA(beta_sol, xmat, y, lamb, L, eta, tol = tol, max_iter = 5000,dtype=torch.float64)\n",
    "    t2 = time.time()\n",
    "\n",
    "    comp_time_torch[i,0] = t2 - t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9754f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  2.1115055084228516\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  0.23238754272460938\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  0.22502660751342773\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  0.22482514381408691\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  0.26065564155578613\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  0.27126145362854004\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  0.22214579582214355\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  0.2237236499786377\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  0.22644615173339844\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  0.2279040813446045\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  0.22399330139160156\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def soft_thr(x, alpha):\n",
    "    n = x.shape[0]\n",
    "    S = torch.maximum(x-alpha, \n",
    "        torch.zeros(n,device='cuda:0'))*torch.sign(x)\n",
    "    return S\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L, eta , tol = 1e-04, max_iter = 5000, dtype = torch.float32):\n",
    "    if(dtype == torch.float32):\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    else:\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    dbeta = torch.Tensor(beta).to(device)\n",
    "    dX = torch.Tensor(X).to(device)\n",
    "    dy = torch.Tensor(y).to(device)\n",
    "    t = torch.ones(1,dtype=dtype, device=device)\n",
    "    crit = np.zeros(max_iter)\n",
    "    dbeta_p = torch.Tensor(beta).to(device)\n",
    "    dbeta_prev = torch.Tensor(beta).to(device)\n",
    "    L_prev = L\n",
    "    for k in range(max_iter):\n",
    "        dymXbp = dy-torch.matmul(dX,dbeta_p)\n",
    "        drbp = torch.dot(dymXbp, dymXbp)\n",
    "        dXTrbp = torch.matmul(torch.t(dX),dymXbp)\n",
    "\n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            L_cur = L_prev*(eta**i_k)\n",
    "            dbstar = dbeta_p + dXTrbp/L_cur\n",
    "            dbeta = soft_thr(dbstar, lamb/L_cur)\n",
    "            diff_beta = dbeta - dbeta_p\n",
    "            RHS_1st = torch.dot(diff_beta,diff_beta)\n",
    "            RHS_2nd = torch.dot(diff_beta,dXTrbp)\n",
    "            RHS = L_cur*RHS_1st-2.0*RHS_2nd\n",
    "            dymXb = dy-torch.matmul(dX,dbeta)\n",
    "            LHS = torch.dot(dymXb,dymXb)-drbp\n",
    "            cond = (LHS>RHS)\n",
    "        L_prev = L_cur\n",
    "        tnext = (1.0+torch.sqrt(1+4*t**2))/2.0\n",
    "        diff_beta = dbeta-dbeta_prev\n",
    "        t1 = (t-1.0)/tnext\n",
    "        dbeta_p = dbeta+t1*diff_beta\n",
    "        crit[k] = torch.norm(diff_beta)\n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "        t = tnext\n",
    "        dbeta_prev = dbeta\n",
    "    out = dbeta.to('cpu')\n",
    "    return out.numpy(), crit, k\n",
    "\n",
    "n = 100\n",
    "p = 200\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "niter = 11\n",
    "comp_time_torch = np.zeros(niter)\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float64)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float64)\n",
    "    L = np.float64(10)\n",
    "    eta = np.float64(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out = FISTA(beta, X, y, lam, L, eta, tol = 1e-04, max_iter = 5000, dtype=torch.float64)\n",
    "    t2 = time.time()\n",
    "    comp_time_torch[i] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_torch[i])\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00296d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF20",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
