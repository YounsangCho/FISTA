{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42e63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = 3000\n",
    "n = int(p/2)\n",
    "niter = 11\n",
    "comp_time_fista = np.zeros((niter,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da22df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  2.9628093242645264\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  2.808971405029297\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  2.8115196228027344\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  2.8106613159179688\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  2.825444459915161\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  2.815269708633423\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  2.8156471252441406\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  2.8087282180786133\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  2.8160183429718018\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  2.8074920177459717\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  2.818000078201294\n"
     ]
    }
   ],
   "source": [
    "from ctypes import *\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "libc_FISTA_dll = CDLL(\"/home/dyu/Dropbox/tf-notebooks/cuda_comp/fista_example/using_dll/fista_dll_double.so\")\n",
    "FISTA_Kernel_D = libc_FISTA_dll.FISTA_D\n",
    "\n",
    "FISTA_Kernel_D.restype = None\n",
    "FISTA_Kernel_D.argtypes = (POINTER(c_double), POINTER(c_double), POINTER(c_double), \n",
    "                         POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_double),\n",
    "                         POINTER(c_int), POINTER(c_int),POINTER(c_int),POINTER(c_int))\n",
    "\n",
    "\n",
    "\n",
    "for i in np.arange(niter):\n",
    "    beta = np.zeros(p).astype(np.float64)\n",
    "    beta_cr = beta.ctypes.data_as(POINTER(c_double))\n",
    "    X_cr =  X.ctypes.data_as(POINTER(c_double)) \n",
    "    y_cr = y.ctypes.data_as(POINTER(c_double))\n",
    "\n",
    "\n",
    "    loss = np.zeros(5000).astype(np.float64)## max_iter size만큼\n",
    "    loss_c = loss.ctypes.data_as(POINTER(c_double)) \n",
    "    lam =  np.sqrt(2 * np.log(p) / n)\n",
    "    lam_c = c_double(lam)\n",
    "    L_c = c_double(10)\n",
    "    eta_c = c_double(2.0)\n",
    "    tol_c = c_double(1e-03)\n",
    "\n",
    "    iter_c = c_int(5000)\n",
    "    n_c = c_int(n)\n",
    "    p_c = c_int(p)\n",
    "    step_c = c_int(0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    FISTA_Kernel_D(beta_cr, X_cr, y_cr, lam_c, L_c, eta_c, tol_c, loss_c, iter_c, n_c, p_c, step_c)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,0] = t2-t1\n",
    "\n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2f82a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_int(1764)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7833879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9540745654624302,\n",
       " 0.9769645522846867,\n",
       " 0.9527462243312763,\n",
       " 0.9482421034939036,\n",
       " 1.0477021786729235]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_cr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2514a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  1.1256682872772217\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  0.8197908401489258\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  0.8013098239898682\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  0.7864444255828857\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  0.8005800247192383\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  0.810218095779419\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  0.7859656810760498\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  0.7888820171356201\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  0.7885239124298096\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  0.8153805732727051\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  0.7951254844665527\n"
     ]
    }
   ],
   "source": [
    "from ctypes import *\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "libc_FISTA_blas = CDLL(\"/home/dyu/Dropbox/tf-notebooks/cuda_comp/fista_example/using_dll/fista_cublas_double.so\")\n",
    "FISTA_blas = libc_FISTA_blas.FISTA\n",
    "\n",
    "FISTA_blas.restype = None\n",
    "FISTA_blas.argtypes = (POINTER(c_double), POINTER(c_double), POINTER(c_double), \n",
    "                         POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_double),\n",
    "                         POINTER(c_int), POINTER(c_int),POINTER(c_int),POINTER(c_int))\n",
    "\n",
    "for i in np.arange(niter):\n",
    "    \n",
    "    beta = np.zeros(p).astype(np.float64)\n",
    "    beta_cc = beta.ctypes.data_as(POINTER(c_double))\n",
    "    X_c =  X.ravel(order = \"F\")              ## n*p 에 () 반드시 필요, c_double * dim 형태만 지원 \n",
    "    X_cc = X_c.ctypes.data_as(POINTER(c_double))\n",
    "    y_cc = y.ctypes.data_as(POINTER(c_double))\n",
    "\n",
    "    loss = np.zeros(5000).astype(np.float64)## max_iter size만큼\n",
    "    loss_c = loss.ctypes.data_as(POINTER(c_double)) \n",
    "    lam =  np.sqrt(2 * np.log(p) / n).astype(np.float64)\n",
    "    lam_c = c_double(lam)\n",
    "    L_c = c_double(10)\n",
    "    eta_c = c_double(2.0)\n",
    "    tol_c = c_double(1e-03)\n",
    "\n",
    "    iter_c = c_int(5000)\n",
    "    n_c = c_int(n)\n",
    "    p_c = c_int(p)\n",
    "    step_c = c_int(0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    FISTA_blas(beta_cc, X_cc, y_cc, lam_c, L_c, eta_c, tol_c, loss_c, iter_c, n_c, p_c, step_c)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,1] = t2-t1\n",
    "\n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31068878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_int(1741)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528c6198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9553229786941347,\n",
       " 0.9786208047010384,\n",
       " 0.9601231139438773,\n",
       " 0.9494173752605825,\n",
       " 1.0526504581998382]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_cc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  5.43377685546875\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  4.752575397491455\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  4.741160154342651\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  4.670172929763794\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  4.850614070892334\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  4.861163854598999\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  4.772057771682739\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  4.741984128952026\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  4.869396686553955\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  4.714514255523682\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  4.935123682022095\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "from pycuda import gpuarray, tools, cumath\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "with open('/home/dyu/Dropbox/tf-notebooks/cuda_comp/fista_example/pycuda/FISTA_kernel.cu') as f:\n",
    "    FISTA_kernel = f.read()\n",
    "    \n",
    "FISTA_module = SourceModule(FISTA_kernel)\n",
    "\n",
    "Dgemv = FISTA_module.get_function(\"Dgemv\")\n",
    "soft_thresh_D = FISTA_module.get_function(\"soft_thresh_D\")\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "\n",
    "def FISTA_D(beta, X, y, lam, L, eta, tol = 1e-04, max_iter = 5000):\n",
    "    n = np.int32(X.shape[0])\n",
    "    p = np.int32(X.shape[1])\n",
    "    t = np.float64(1.0)\n",
    "    One = np.float64(1.0)\n",
    "    MOne = np.float64(-1.0)\n",
    "    IntOne = np.int32(1)\n",
    "    IntZero = np.int32(0)\n",
    "    \n",
    "    crit = np.zeros(max_iter, dtype=np.float64)\n",
    "    temp = np.zeros(p, dtype=np.float64)\n",
    "    d_beta_p = gpuarray.to_gpu(temp)\n",
    "    d_beta_prev = gpuarray.to_gpu(temp)\n",
    "    d_X = gpuarray.to_gpu(X)\n",
    "    d_y = gpuarray.to_gpu(y)\n",
    "    d_ymXbp = gpuarray.empty(n, dtype = np.float64)\n",
    "    d_beta = gpuarray.empty(p, dtype = np.float64)\n",
    "  \n",
    "    TPB = (32, 1, 1)\n",
    "    bpg_p = math.ceil(np.float64(p)/TPB[0])\n",
    "    bpg_n = math.ceil(np.float64(n)/TPB[0])\n",
    "    BPG_p = (bpg_p, 1, 1)\n",
    "    BPG_n = (bpg_n, 1, 1)\n",
    "  \n",
    "    L_prev = L\n",
    "    for k in range(max_iter):\n",
    "        d_ymXbp = d_y.copy()\n",
    "        Dgemv(MOne, d_X, d_beta_p, \n",
    "              d_ymXbp, n, p, IntZero,\n",
    "              grid = BPG_n, block = TPB)\n",
    "        h_rbp = gpuarray.dot(d_ymXbp, d_ymXbp)\n",
    "        d_XTrbp = gpuarray.zeros(p, np.float64)\n",
    "        Dgemv(One, d_X, d_ymXbp, d_XTrbp, n, p,\n",
    "              IntOne, grid = BPG_p, block = TPB)\n",
    "        \n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            eta_ik = eta ** i_k\n",
    "            L_cur = L_prev * eta_ik\n",
    "            alpha = np.float64(1.0/L_cur)  \n",
    "            d_bstar = d_beta_p + alpha*d_XTrbp\n",
    "            alpha = np.float64(lam/L_cur)\n",
    "            soft_thresh_D(d_bstar, alpha, d_beta, p,\n",
    "                         grid = BPG_p, block = TPB)\n",
    "            d_diff_beta = d_beta - d_beta_p\n",
    "            h_RHS_1st = gpuarray.dot(d_diff_beta,\n",
    "                                     d_diff_beta)\n",
    "            h_RHS_2nd = gpuarray.dot(d_diff_beta,\n",
    "                                     d_XTrbp)\n",
    "              \n",
    "            RHS1 = L_cur * h_RHS_1st.get()\n",
    "            RHS2 = np.float32(2.0)*h_RHS_2nd.get()\n",
    "            RHS =  RHS1 - RHS2 \n",
    "                              \n",
    "            d_ymXb = d_y.copy()\n",
    "            Dgemv(MOne, d_X, d_beta, d_ymXb, n, p, \n",
    "                  IntZero, grid = BPG_n, block = TPB)\n",
    "            d_ymXb2 = gpuarray.dot(d_ymXb, d_ymXb)\n",
    "            LHS = d_ymXb2.get() - h_rbp.get()\n",
    "            cond = (LHS > RHS)\n",
    "          \n",
    "        L_prev = L_cur\n",
    "        tnext = np.float64((1.0+np.sqrt(1+4*t*t))/2)\n",
    "        d_diff_beta = d_beta - d_beta_prev\n",
    "        alpha = np.float64((t - 1.0)/tnext)\n",
    "        d_beta_p = d_beta + alpha * d_diff_beta\n",
    "        d_diff_b_sq = gpuarray.dot(d_diff_beta,\n",
    "                                   d_diff_beta)\n",
    "        crit[k] = np.sqrt(d_diff_b_sq.get())\n",
    "          \n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "          \n",
    "        t = tnext\n",
    "        d_beta_prev = d_beta.copy()\n",
    "          \n",
    "    return d_beta.get(), crit, k\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float64)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float64)\n",
    "    L = np.float64(10)\n",
    "    eta = np.float64(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out, crit, step = FISTA_D(beta, X, y, lam, L, eta, tol = 1e-3, max_iter = 5000)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,2] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ac3363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c959a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95591871, 0.97639646, 0.95139887, 0.95003793, 1.05218448])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca579a32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  113.32188868522644\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  113.04587888717651\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  113.21139931678772\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  111.98239946365356\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  112.53168272972107\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  113.60604357719421\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  113.19279909133911\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  112.07095694541931\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  112.46536064147949\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  111.88113498687744\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  112.5671615600586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "@cuda.jit\n",
    "def gemv(alpha, A, x, y, tran):\n",
    "    Row = cuda.grid(1)\n",
    "    n = A.shape[0]\n",
    "    p = A.shape[1]\n",
    "    pvalue = 0.\n",
    "    if tran:\n",
    "        if Row < p:\n",
    "            for i in range(n):\n",
    "                pvalue += A[i, Row] * x[i]\n",
    "            y[Row] += alpha * pvalue\n",
    "    else:\n",
    "        if Row < n:\n",
    "            for j in range(p):\n",
    "                pvalue += A[Row, j] * x[j]\n",
    "            y[Row] += alpha * pvalue\n",
    "\n",
    "@cuda.jit\n",
    "def soft_thr(x, alpha, S):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < x.shape[0]:\n",
    "        thr = math.fabs(x[idx]) - alpha\n",
    "        if thr > 0:\n",
    "            S[idx] = math.copysign(thr, x[idx])\n",
    "        else:\n",
    "            S[idx] = 0\n",
    "\n",
    "@cuda.jit\n",
    "def axpy(alpha, x, y):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < x.shape[0]:\n",
    "        y[idx] += alpha * x[idx]\n",
    "\n",
    "        \n",
    "@cuda.jit\n",
    "def vec_prod(x, y, res):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < x.shape[0]:\n",
    "        res[idx] = x[idx] * y[idx]\n",
    "\n",
    "@cuda.reduce\n",
    "def reduce(x, y):\n",
    "    return x+y\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L = 10, eta = 1.2, tol = 1e-08, \n",
    "          max_iter = 5000, dtype = np.float32):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    t = dtype(1.0)\n",
    "    crit = np.zeros(max_iter, dtype = dtype)\n",
    "    d_bstar = np.zeros(p, dtype = dtype)\n",
    "    d_beta = np.zeros(p, dtype = dtype)\n",
    "    d_diff_beta2 = np.zeros(p, dtype = dtype)\n",
    "    d_XTrbpd = np.zeros(p, dtype = dtype)\n",
    "    d_beta_prev = np.zeros(p,dtype = dtype)\n",
    "    d_beta_p = np.zeros(p, dtype = dtype)\n",
    "    d_ymXbp2 = np.zeros(n, dtype = dtype)\n",
    "    d_ymXb2= np.zeros(n, dtype = dtype)\n",
    "    L_prev = L\n",
    "    TPB = (32,1)\n",
    "    BPG_p = (math.ceil(p / 32) , 1)\n",
    "    BPG_n = (math.ceil(n / 32) , 1)\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        d_ymXbp = y.copy()\n",
    "        gemv[BPG_n, TPB](-1.0, X, d_beta_p, d_ymXbp, False)\n",
    "        vec_prod[BPG_n, TPB](d_ymXbp, d_ymXbp, d_ymXbp2)\n",
    "        h_rbp = reduce(d_ymXbp2)\n",
    "        d_XTrbp = np.zeros(p, dtype = dtype)\n",
    "        gemv[BPG_p, TPB](1.0, X, d_ymXbp, d_XTrbp, True)\n",
    "        \n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            L_cur = L_prev * (eta ** i_k)\n",
    "            d_bstar = d_beta_p.copy()\n",
    "            axpy[BPG_p, TPB]((1.0 / L_cur), d_XTrbp, d_bstar)\n",
    "            soft_thr[BPG_p, TPB](d_bstar, lamb / L_cur, d_beta)\n",
    "            d_diff_beta = d_beta.copy()\n",
    "            axpy[BPG_p, TPB](-1.0, d_beta_p, d_diff_beta)\n",
    "            vec_prod[BPG_p, TPB](d_diff_beta, d_diff_beta, d_diff_beta2)\n",
    "            vec_prod[BPG_p, TPB](d_XTrbp, d_diff_beta, d_XTrbpd)\n",
    "            RHS = L_cur * reduce(d_diff_beta2) - 2.0 * reduce(d_XTrbpd)\n",
    "            d_ymXb = y.copy()\n",
    "            gemv[BPG_n, TPB](-1.0, X, d_beta, d_ymXb, False)\n",
    "            vec_prod[BPG_n, TPB](d_ymXb, d_ymXb, d_ymXb2)\n",
    "            h_rb = reduce(d_ymXb2)\n",
    "            LHS =  h_rb - h_rbp\n",
    "            cond = (LHS > RHS)\n",
    "        \n",
    "        L_prev = L_cur\n",
    "        tnext = (1.0 + np.sqrt(1 + 4 * t**2) ) / 2.0\n",
    "        d_diff_beta = d_beta.copy()\n",
    "        axpy[BPG_p, TPB](-1.0, d_beta_prev, d_diff_beta)\n",
    "        t1 = (t - 1.0) / tnext\n",
    "        d_beta_p = d_beta.copy()\n",
    "        axpy[BPG_p, TPB](t1, d_diff_beta, d_beta_p)\n",
    "        vec_prod[BPG_p, TPB](d_diff_beta, d_diff_beta, d_diff_beta2)\n",
    "        crit[k] = np.sqrt(reduce(d_diff_beta2))\n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "        t = tnext\n",
    "        d_beta_prev = d_beta.copy()\n",
    "    return d_beta, crit, k\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "cuda.select_device(0)\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float64)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float64)\n",
    "    L = np.float64(10)\n",
    "    eta = np.float64(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out, crit, step = FISTA(beta, X, y, lam, L, eta, tol = 1e-03, max_iter = 5000, dtype=np.float64)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,3] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,3])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5bff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1758"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe3cb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95583119, 0.97726276, 0.95160533, 0.9520176 , 1.05104607])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf8e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  3.04213809967041\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  1.127195119857788\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  1.107191562652588\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  1.2018523216247559\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  1.0588312149047852\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  1.0352919101715088\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  1.051959753036499\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  1.2226064205169678\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  1.0293498039245605\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  1.0370068550109863\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  1.120659351348877\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.init()\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "\n",
    "def soft_thr(x, alpha):\n",
    "    n = x.shape[0]\n",
    "    S = torch.maximum(torch.abs(x)-alpha, \n",
    "        torch.zeros(n,device='cuda:0'))*torch.sign(x)\n",
    "    return S\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L, eta , tol = 1e-04, max_iter = 5000, dtype = torch.float32):\n",
    "    if(dtype == torch.float32):\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    else:\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    dbeta = torch.Tensor(beta).to(device)\n",
    "    dX = torch.Tensor(X).to(device)\n",
    "    dy = torch.Tensor(y).to(device)\n",
    "    t = torch.ones(1,dtype=dtype, device=device)\n",
    "    crit = np.zeros(max_iter)\n",
    "    dbeta_p = torch.Tensor(beta).to(device)\n",
    "    dbeta_prev = torch.Tensor(beta).to(device)\n",
    "    L_prev = L\n",
    "    for k in range(max_iter):\n",
    "        dymXbp = dy-torch.matmul(dX,dbeta_p)\n",
    "        drbp = torch.dot(dymXbp, dymXbp)\n",
    "        dXTrbp = torch.matmul(torch.t(dX),dymXbp)\n",
    "\n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            L_cur = L_prev*(eta**i_k)\n",
    "            dbstar = dbeta_p + dXTrbp/L_cur\n",
    "            dbeta = soft_thr(dbstar, lamb/L_cur)\n",
    "            diff_beta = dbeta - dbeta_p\n",
    "            RHS_1st = torch.dot(diff_beta,diff_beta)\n",
    "            RHS_2nd = torch.dot(diff_beta,dXTrbp)\n",
    "            RHS = L_cur*RHS_1st-2.0*RHS_2nd\n",
    "            dymXb = dy-torch.matmul(dX,dbeta)\n",
    "            LHS = torch.dot(dymXb,dymXb)-drbp\n",
    "            cond = (LHS>RHS)\n",
    "        L_prev = L_cur\n",
    "        tnext = (1.0+torch.sqrt(1+4*t**2))/2.0\n",
    "        diff_beta = dbeta-dbeta_prev\n",
    "        t1 = (t-1.0)/tnext\n",
    "        dbeta_p = dbeta+t1*diff_beta\n",
    "        crit[k] = torch.linalg.norm(diff_beta).to('cpu')\n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "        t = tnext\n",
    "        dbeta_prev = dbeta\n",
    "    out = dbeta.to('cpu')\n",
    "    return out.numpy(), crit, k\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float64)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float64)\n",
    "    L = np.float64(10)\n",
    "    eta = np.float64(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out,crit,step = FISTA(beta, X, y, lam, L, eta, tol = 1e-03, max_iter = 5000, dtype = torch.float64)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,5] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,5])\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b0cf10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7822bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95254066, 0.9785757 , 0.95588044, 0.95169777, 1.05268715])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36782ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.14292947, 1.54338943, 1.21923763, 0.96647247, 0.78125418,\n",
       "       0.64401647, 0.53842078, 0.45384516, 0.38440976])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e66f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2371c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  8.79351019859314\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  6.609880447387695\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  6.880760431289673\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  6.944295883178711\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  6.326539516448975\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  6.387064456939697\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  6.358918190002441\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  6.475696563720703\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  6.693721055984497\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  8.371906518936157\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  7.335567951202393\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "@tf.function\n",
    "def soft_thr(x,alpha):\n",
    "    n = x.shape[0]\n",
    "    S = tf.math.maximum(tf.abs(x)-alpha,0)*tf.math.sign(x)\n",
    "    return S\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L, eta, tol = 1e-08, max_iter = 5000, dtype = tf.float32):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    crit = np.zeros(max_iter)\n",
    "  \n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        dbeta = tf.constant(beta)\n",
    "        dX = tf.constant(X)\n",
    "        dy = tf.constant(y)\n",
    "        t = tf.constant(1.0, dtype=dtype)\n",
    "        dbeta_p = tf.constant(beta)\n",
    "        dbeta_prev = tf.constant(beta)\n",
    "        L_prev = tf.constant(L,dtype=dtype)\n",
    "\n",
    "        for k in range(max_iter):\n",
    "            dymXbp = dy-tf.linalg.matvec(dX,dbeta_p)\n",
    "            drbp = tf.tensordot(dymXbp,dymXbp,axes=1)\n",
    "            dXTrbp = tf.linalg.matvec(dX,dymXbp, \n",
    "                                    transpose_a=True)\n",
    "\n",
    "            i_k = -1\n",
    "            cond = True\n",
    "            while cond:\n",
    "                i_k += 1\n",
    "                L_cur = L_prev*(eta**i_k)\n",
    "                dbstar = dbeta_p + dXTrbp/L_cur\n",
    "                dbeta = soft_thr(dbstar, lamb/L_cur)\n",
    "                diff_beta = dbeta - dbeta_p\n",
    "                RHS_1st = tf.tensordot(diff_beta, \n",
    "                                       diff_beta,axes=1)\n",
    "                RHS_2nd = tf.tensordot(diff_beta, dXTrbp,\n",
    "                                       axes=1)\n",
    "                RHS = L_cur * RHS_1st.numpy() - 2.0 * RHS_2nd.numpy()\n",
    "                dymXb = dy - tf.linalg.matvec(dX,dbeta)\n",
    "                LHS = (tf.tensordot(dymXb,dymXb,\n",
    "                       axes=1)).numpy()-drbp.numpy()\n",
    "                cond = (LHS>RHS)\n",
    "            L_prev = L_cur\n",
    "            tnext =  (1.0+tf.sqrt(1+4*t**2))/2.0\n",
    "            diff_beta = dbeta-dbeta_prev\n",
    "            t1 = (t - 1.0)/tnext\n",
    "            dbeta_p = dbeta+t1*diff_beta\n",
    "            crit[k] = tf.norm(diff_beta) \n",
    "            if crit[k] < tol:\n",
    "                break\n",
    "            t = tnext\n",
    "            dbeta_prev = dbeta\n",
    "    return dbeta.numpy(), crit, k\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float64)\n",
    "tr_beta = np.zeros(p).astype(np.float64)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float64)\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float64)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float64)\n",
    "    L = np.float64(10)\n",
    "    eta = np.float64(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out, crit, step = FISTA(beta, X, y, lam, L, eta, tol = 1e-03, max_iter = 5000, dtype=tf.float64)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,4] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,4])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7eb5ae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "858aa83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96021451, 0.97877206, 0.95417989, 0.95321325, 1.05189365])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78795e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./fista_comp_time_n{}_p{}_double.txt'.format(n,p), 'w') as f:\n",
    "    print(('%s\\t '*6 % ('DLL-K','DLL-cuBLAS','PyCUDA','Numba','TF','PyTorch')), end='\\n', file=f)\n",
    "    for i in range(niter):\n",
    "        print(('%.4f\\t '*6 % tuple(comp_time_fista[i])), end='\\n', file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc0d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF20",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
