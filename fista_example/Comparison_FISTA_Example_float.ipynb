{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42e63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = 3000\n",
    "n = int(p/2)\n",
    "niter = 11\n",
    "comp_time_fista = np.zeros((niter,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da22df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  1.7543652057647705\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  1.626410722732544\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  1.6284685134887695\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  1.628798246383667\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  1.6242821216583252\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  1.6260333061218262\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  1.632284164428711\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  1.6383018493652344\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  1.612287998199463\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  1.6460251808166504\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  1.6154115200042725\n"
     ]
    }
   ],
   "source": [
    "from ctypes import *\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float32)\n",
    "tr_beta = np.zeros(p).astype(np.float32)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float32)\n",
    "\n",
    "libc_FISTA_dll = CDLL(\"/home/dyu/Dropbox/tf-notebooks/cuda_comp/fista_example/using_dll/fista_dll_float.so\")\n",
    "FISTA_Kernel_S = libc_FISTA_dll.FISTA_S\n",
    "\n",
    "FISTA_Kernel_S.restype = None\n",
    "FISTA_Kernel_S.argtypes = (POINTER(c_float), POINTER(c_float), POINTER(c_float), \n",
    "                         POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float),\n",
    "                         POINTER(c_int), POINTER(c_int),POINTER(c_int),POINTER(c_int))\n",
    "\n",
    "\n",
    "\n",
    "for i in np.arange(niter):\n",
    "    beta = np.zeros(p).astype(np.float32)\n",
    "    beta_cr = beta.ctypes.data_as(POINTER(c_float))\n",
    "    X_cr =  X.ctypes.data_as(POINTER(c_float)) \n",
    "    y_cr = y.ctypes.data_as(POINTER(c_float))\n",
    "\n",
    "\n",
    "    loss = np.zeros(5000).astype(np.float32)## max_iter size만큼\n",
    "    loss_c = loss.ctypes.data_as(POINTER(c_float)) \n",
    "    lam =  np.sqrt(2 * np.log(p) / n)\n",
    "    lam_c = c_float(lam)\n",
    "    L_c = c_float(10)\n",
    "    eta_c = c_float(2.0)\n",
    "    tol_c = c_float(1e-03)\n",
    "\n",
    "    iter_c = c_int(5000)\n",
    "    n_c = c_int(n)\n",
    "    p_c = c_int(p)\n",
    "    step_c = c_int(0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    FISTA_Kernel_S(beta_cr, X_cr, y_cr, lam_c, L_c, eta_c, tol_c, loss_c, iter_c, n_c, p_c, step_c)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,0] = t2-t1\n",
    "\n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2f82a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_int(1746)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7833879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9535295963287354,\n",
       " 0.9764904379844666,\n",
       " 0.9542718529701233,\n",
       " 0.9487429857254028,\n",
       " 1.050582766532898]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_cr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b354a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.142929792404175,\n",
       " 1.5433892011642456,\n",
       " 1.2192375659942627,\n",
       " 0.9664725065231323,\n",
       " 0.7812541127204895]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_c[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2514a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  0.7872188091278076\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  0.4914968013763428\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  0.5087156295776367\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  0.4932122230529785\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  0.513617992401123\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  0.4919900894165039\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  0.5067856311798096\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  0.49361395835876465\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  0.4910733699798584\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  0.5302181243896484\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  0.4998292922973633\n"
     ]
    }
   ],
   "source": [
    "from ctypes import *\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float32)\n",
    "tr_beta = np.zeros(p).astype(np.float32)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float32)\n",
    "\n",
    "libc_FISTA_blas = CDLL(\"/home/dyu/Dropbox/tf-notebooks/cuda_comp/fista_example/using_dll/fista_cublas_float.so\")\n",
    "FISTA_blas = libc_FISTA_blas.FISTA\n",
    "\n",
    "FISTA_blas.restype = None\n",
    "FISTA_blas.argtypes = (POINTER(c_float), POINTER(c_float), POINTER(c_float), \n",
    "                         POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float), POINTER(c_float),\n",
    "                         POINTER(c_int), POINTER(c_int),POINTER(c_int),POINTER(c_int))\n",
    "\n",
    "for i in np.arange(niter):\n",
    "    \n",
    "    beta = np.zeros(p).astype(np.float32)\n",
    "    beta_cc = beta.ctypes.data_as(POINTER(c_float))\n",
    "    X_c =  X.ravel(order = \"F\")              ## n*p 에 () 반드시 필요, c_double * dim 형태만 지원 \n",
    "    X_cc = X_c.ctypes.data_as(POINTER(c_float))\n",
    "    y_cc = y.ctypes.data_as(POINTER(c_float))\n",
    "\n",
    "    loss = np.zeros(5000).astype(np.float32)## max_iter size만큼\n",
    "    loss_c = loss.ctypes.data_as(POINTER(c_float)) \n",
    "    lam =  np.sqrt(2 * np.log(p) / n).astype(np.float32)\n",
    "    lam_c = c_float(lam)\n",
    "    L_c = c_float(10.0)\n",
    "    eta_c = c_float(2.0)\n",
    "    tol_c = c_float(1e-03)\n",
    "\n",
    "    iter_c = c_int(5000)\n",
    "    n_c = c_int(n)\n",
    "    p_c = c_int(p)\n",
    "    step_c = c_int(0)\n",
    "\n",
    "    t1 = time.time()\n",
    "    FISTA_blas(beta_cc, X_cc, y_cc, lam_c, L_c, eta_c, tol_c, loss_c, iter_c, n_c, p_c, step_c)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,1] = t2-t1\n",
    "\n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31068878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_int(1743)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528c6198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9540179371833801,\n",
       " 0.9741050601005554,\n",
       " 0.9583085775375366,\n",
       " 0.9486698508262634,\n",
       " 1.0489410161972046]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_cc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65d2c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.142929792404175,\n",
       " 1.5433893203735352,\n",
       " 1.2192375659942627,\n",
       " 0.9664724469184875,\n",
       " 0.7812541127204895]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_c[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  4.30243182182312\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  3.577413558959961\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  3.624744415283203\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  3.655689239501953\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  3.7542014122009277\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  3.6771984100341797\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  3.700299024581909\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  3.5761942863464355\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  3.650284767150879\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  3.4707753658294678\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  3.5973548889160156\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "from pycuda import gpuarray, tools, cumath\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "with open('/home/dyu/Dropbox/tf-notebooks/cuda_comp/fista_example/pycuda/FISTA_kernel.cu') as f:\n",
    "    FISTA_kernel = f.read()\n",
    "    \n",
    "FISTA_module = SourceModule(FISTA_kernel)\n",
    "\n",
    "Sgemv = FISTA_module.get_function(\"Sgemv\")\n",
    "soft_thresh_S = FISTA_module.get_function(\"soft_thresh_S\")\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float32)\n",
    "tr_beta = np.zeros(p).astype(np.float32)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float32)\n",
    "\n",
    "\n",
    "def FISTA_S(beta, X, y, lam, L, eta, tol = 1e-04, max_iter = 5000):\n",
    "    n = np.int32(X.shape[0])\n",
    "    p = np.int32(X.shape[1])\n",
    "    t = np.float32(1.0)\n",
    "    One = np.float32(1.0)\n",
    "    MOne = np.float32(-1.0)\n",
    "    IntOne = np.int32(1)\n",
    "    IntZero = np.int32(0)\n",
    "    \n",
    "    crit = np.zeros(max_iter, dtype=np.float32)\n",
    "    temp = np.zeros(p, dtype=np.float32)\n",
    "    d_beta_p = gpuarray.to_gpu(temp)\n",
    "    d_beta_prev = gpuarray.to_gpu(temp)\n",
    "    d_X = gpuarray.to_gpu(X)\n",
    "    d_y = gpuarray.to_gpu(y)\n",
    "    d_ymXbp = gpuarray.empty(n, dtype = np.float32)\n",
    "    d_beta = gpuarray.empty(p, dtype = np.float32)\n",
    "  \n",
    "    TPB = (32, 1, 1)\n",
    "    bpg_p = math.ceil(np.float32(p)/TPB[0])\n",
    "    bpg_n = math.ceil(np.float32(n)/TPB[0])\n",
    "    BPG_p = (bpg_p, 1, 1)\n",
    "    BPG_n = (bpg_n, 1, 1)\n",
    "  \n",
    "    L_prev = L\n",
    "    for k in range(max_iter):\n",
    "        d_ymXbp = d_y.copy()\n",
    "        Sgemv(MOne, d_X, d_beta_p, \n",
    "              d_ymXbp, n, p, IntZero,\n",
    "              grid = BPG_n, block = TPB)\n",
    "        h_rbp = gpuarray.dot(d_ymXbp, d_ymXbp)\n",
    "        d_XTrbp = gpuarray.zeros(p, np.float32)\n",
    "        Sgemv(One, d_X, d_ymXbp, d_XTrbp, n, p,\n",
    "              IntOne, grid = BPG_p, block = TPB)\n",
    "        \n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            eta_ik = eta ** i_k\n",
    "            L_cur = L_prev * eta_ik\n",
    "            alpha = np.float32(1.0/L_cur)  \n",
    "            d_bstar = d_beta_p + alpha*d_XTrbp\n",
    "            alpha = np.float32(lam/L_cur)\n",
    "            soft_thresh_S(d_bstar, alpha, d_beta, p,\n",
    "                         grid = BPG_p, block = TPB)\n",
    "            d_diff_beta = d_beta - d_beta_p\n",
    "            h_RHS_1st = gpuarray.dot(d_diff_beta,\n",
    "                                     d_diff_beta)\n",
    "            h_RHS_2nd = gpuarray.dot(d_diff_beta,\n",
    "                                     d_XTrbp)\n",
    "              \n",
    "            RHS1 = L_cur * h_RHS_1st.get()\n",
    "            RHS2 = np.float32(2.0)*h_RHS_2nd.get()\n",
    "            RHS =  RHS1 - RHS2 \n",
    "                              \n",
    "            d_ymXb = d_y.copy()\n",
    "            Sgemv(MOne, d_X, d_beta, d_ymXb, n, p, \n",
    "                  IntZero, grid = BPG_n, block = TPB)\n",
    "            d_ymXb2 = gpuarray.dot(d_ymXb, d_ymXb)\n",
    "            LHS = d_ymXb2.get() - h_rbp.get()\n",
    "            cond = (LHS > RHS)\n",
    "          \n",
    "        L_prev = L_cur\n",
    "        tnext = np.float32((1.0+np.sqrt(1+4*t*t))/2)\n",
    "        d_diff_beta = d_beta - d_beta_prev\n",
    "        alpha = np.float32((t - 1.0)/tnext)\n",
    "        d_beta_p = d_beta + alpha * d_diff_beta\n",
    "        d_diff_b_sq = gpuarray.dot(d_diff_beta,\n",
    "                                   d_diff_beta)\n",
    "        crit[k] = np.sqrt(d_diff_b_sq.get())\n",
    "          \n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "          \n",
    "        t = tnext\n",
    "        d_beta_prev = d_beta.copy()\n",
    "          \n",
    "    return d_beta.get(), crit, k\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float32)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float32)\n",
    "    L = np.float32(10)\n",
    "    eta = np.float32(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out, crit, step = FISTA_S(beta, X, y, lam, L, eta, tol = 1e-3, max_iter = 5000)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,2] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ac3363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c959a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9498172 , 0.97780025, 0.94975954, 0.9497829 , 1.0544457 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca579a32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  79.7794075012207\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  78.54222583770752\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  78.82252240180969\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  79.10402488708496\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  79.04960012435913\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  79.51575303077698\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  78.22756361961365\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  79.01998257637024\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  79.4259901046753\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  79.55859065055847\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  78.1091775894165\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "@cuda.jit\n",
    "def gemv(alpha, A, x, y, tran):\n",
    "    Row = cuda.grid(1)\n",
    "    n = A.shape[0]\n",
    "    p = A.shape[1]\n",
    "    pvalue = 0.\n",
    "    if tran:\n",
    "        if Row < p:\n",
    "            for i in range(n):\n",
    "                pvalue += A[i, Row] * x[i]\n",
    "            y[Row] += alpha * pvalue\n",
    "    else:\n",
    "        if Row < n:\n",
    "            for j in range(p):\n",
    "                pvalue += A[Row, j] * x[j]\n",
    "            y[Row] += alpha * pvalue\n",
    "\n",
    "@cuda.jit\n",
    "def soft_thr(x, alpha, S):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < x.shape[0]:\n",
    "        thr = math.fabs(x[idx]) - alpha\n",
    "        if thr > 0:\n",
    "            S[idx] = math.copysign(thr, x[idx])\n",
    "        else:\n",
    "            S[idx] = 0\n",
    "\n",
    "@cuda.jit\n",
    "def axpy(alpha, x, y):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < x.shape[0]:\n",
    "        y[idx] += alpha * x[idx]\n",
    "\n",
    "        \n",
    "@cuda.jit\n",
    "def vec_prod(x, y, res):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < x.shape[0]:\n",
    "        res[idx] = x[idx] * y[idx]\n",
    "\n",
    "@cuda.reduce\n",
    "def reduce(x, y):\n",
    "    return x+y\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L = 10, eta = 1.2, tol = 1e-08, \n",
    "          max_iter = 5000, dtype = np.float32):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    t = dtype(1.0)\n",
    "    crit = np.zeros(max_iter, dtype = dtype)\n",
    "    d_bstar = np.zeros(p, dtype = dtype)\n",
    "    d_beta = np.zeros(p, dtype = dtype)\n",
    "    d_diff_beta2 = np.zeros(p, dtype = dtype)\n",
    "    d_XTrbpd = np.zeros(p, dtype = dtype)\n",
    "    d_beta_prev = np.zeros(p,dtype = dtype)\n",
    "    d_beta_p = np.zeros(p, dtype = dtype)\n",
    "    d_ymXbp2 = np.zeros(n, dtype = dtype)\n",
    "    d_ymXb2= np.zeros(n, dtype = dtype)\n",
    "    L_prev = L\n",
    "    TPB = (32,1)\n",
    "    BPG_p = (math.ceil(p / 32) , 1)\n",
    "    BPG_n = (math.ceil(n / 32) , 1)\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        d_ymXbp = y.copy()\n",
    "        gemv[BPG_n, TPB](-1.0, X, d_beta_p, d_ymXbp, False)\n",
    "        vec_prod[BPG_n, TPB](d_ymXbp, d_ymXbp, d_ymXbp2)\n",
    "        h_rbp = reduce(d_ymXbp2)\n",
    "        d_XTrbp = np.zeros(p, dtype = dtype)\n",
    "        gemv[BPG_p, TPB](1.0, X, d_ymXbp, d_XTrbp, True)\n",
    "        \n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            L_cur = L_prev * (eta ** i_k)\n",
    "            d_bstar = d_beta_p.copy()\n",
    "            axpy[BPG_p, TPB]((1.0 / L_cur), d_XTrbp, d_bstar)\n",
    "            soft_thr[BPG_p, TPB](d_bstar, lamb / L_cur, d_beta)\n",
    "            d_diff_beta = d_beta.copy()\n",
    "            axpy[BPG_p, TPB](-1.0, d_beta_p, d_diff_beta)\n",
    "            vec_prod[BPG_p, TPB](d_diff_beta, d_diff_beta, d_diff_beta2)\n",
    "            vec_prod[BPG_p, TPB](d_XTrbp, d_diff_beta, d_XTrbpd)\n",
    "            RHS = L_cur * reduce(d_diff_beta2) - 2.0 * reduce(d_XTrbpd)\n",
    "            d_ymXb = y.copy()\n",
    "            gemv[BPG_n, TPB](-1.0, X, d_beta, d_ymXb, False)\n",
    "            vec_prod[BPG_n, TPB](d_ymXb, d_ymXb, d_ymXb2)\n",
    "            h_rb = reduce(d_ymXb2)\n",
    "            LHS =  h_rb - h_rbp\n",
    "            cond = (LHS > RHS)\n",
    "        \n",
    "        L_prev = L_cur\n",
    "        tnext = (1.0 + np.sqrt(1 + 4 * t**2) ) / 2.0\n",
    "        d_diff_beta = d_beta.copy()\n",
    "        axpy[BPG_p, TPB](-1.0, d_beta_prev, d_diff_beta)\n",
    "        t1 = (t - 1.0) / tnext\n",
    "        d_beta_p = d_beta.copy()\n",
    "        axpy[BPG_p, TPB](t1, d_diff_beta, d_beta_p)\n",
    "        vec_prod[BPG_p, TPB](d_diff_beta, d_diff_beta, d_diff_beta2)\n",
    "        crit[k] = np.sqrt(reduce(d_diff_beta2))\n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "        t = tnext\n",
    "        d_beta_prev = d_beta.copy()\n",
    "    return d_beta, crit, k\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float32)\n",
    "tr_beta = np.zeros(p).astype(np.float32)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float32)\n",
    "\n",
    "cuda.select_device(0)\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float32)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float32)\n",
    "    L = np.float32(10)\n",
    "    eta = np.float32(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out, crit, step = FISTA(beta, X, y, lam, L, eta, tol = 1e-03, max_iter = 5000)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,3] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,3])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c5bff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe3cb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95338017, 0.9755957 , 0.9560744 , 0.9505501 , 1.0496136 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cf8e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  2.9106998443603516\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  0.996375322341919\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  1.0285370349884033\n",
      "\n",
      "  4 -th iteration, Collapsed Time:  0.9759187698364258\n",
      "\n",
      "  5 -th iteration, Collapsed Time:  1.011160135269165\n",
      "\n",
      "  6 -th iteration, Collapsed Time:  0.9376533031463623\n",
      "\n",
      "  7 -th iteration, Collapsed Time:  0.9548244476318359\n",
      "\n",
      "  8 -th iteration, Collapsed Time:  0.9287333488464355\n",
      "\n",
      "  9 -th iteration, Collapsed Time:  0.9455447196960449\n",
      "\n",
      "  10 -th iteration, Collapsed Time:  0.9345541000366211\n",
      "\n",
      "  11 -th iteration, Collapsed Time:  0.9375431537628174\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.init()\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "\n",
    "def soft_thr(x, alpha):\n",
    "    n = x.shape[0]\n",
    "    S = torch.maximum(torch.abs(x)-alpha, \n",
    "        torch.zeros(n,device='cuda:0'))*torch.sign(x)\n",
    "    return S\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L, eta , tol = 1e-04, max_iter = 5000, dtype = torch.float32):\n",
    "    if(dtype == torch.float32):\n",
    "        torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    else:\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    dbeta = torch.Tensor(beta).to(device)\n",
    "    dX = torch.Tensor(X).to(device)\n",
    "    dy = torch.Tensor(y).to(device)\n",
    "    t = torch.ones(1,dtype=dtype, device=device)\n",
    "    crit = np.zeros(max_iter)\n",
    "    dbeta_p = torch.Tensor(beta).to(device)\n",
    "    dbeta_prev = torch.Tensor(beta).to(device)\n",
    "    L_prev = L\n",
    "    for k in range(max_iter):\n",
    "        dymXbp = dy-torch.matmul(dX,dbeta_p)\n",
    "        drbp = torch.dot(dymXbp, dymXbp)\n",
    "        dXTrbp = torch.matmul(torch.t(dX),dymXbp)\n",
    "\n",
    "        i_k = -1\n",
    "        cond = True\n",
    "        while cond:\n",
    "            i_k += 1\n",
    "            L_cur = L_prev*(eta**i_k)\n",
    "            dbstar = dbeta_p + dXTrbp/L_cur\n",
    "            dbeta = soft_thr(dbstar, lamb/L_cur)\n",
    "            diff_beta = dbeta - dbeta_p\n",
    "            RHS_1st = torch.dot(diff_beta,diff_beta)\n",
    "            RHS_2nd = torch.dot(diff_beta,dXTrbp)\n",
    "            RHS = L_cur*RHS_1st-2.0*RHS_2nd\n",
    "            dymXb = dy-torch.matmul(dX,dbeta)\n",
    "            LHS = torch.dot(dymXb,dymXb)-drbp\n",
    "            cond = (LHS>RHS)\n",
    "        L_prev = L_cur\n",
    "        tnext = (1.0+torch.sqrt(1+4*t**2))/2.0\n",
    "        diff_beta = dbeta-dbeta_prev\n",
    "        t1 = (t-1.0)/tnext\n",
    "        dbeta_p = dbeta+t1*diff_beta\n",
    "        crit[k] = torch.linalg.norm(diff_beta).to('cpu')\n",
    "        if crit[k] < tol:\n",
    "            break\n",
    "        t = tnext\n",
    "        dbeta_prev = dbeta\n",
    "    out = dbeta.to('cpu')\n",
    "    return out.numpy(), crit, k\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float32)\n",
    "tr_beta = np.zeros(p).astype(np.float32)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float32)\n",
    "\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float32)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float32)\n",
    "    L = np.float32(10)\n",
    "    eta = np.float32(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out,crit,step = FISTA(beta, X, y, lam, L, eta, tol = 1e-03, max_iter = 5000)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,5] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,5])\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b0cf10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1729"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7822bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9568989 , 0.9750053 , 0.95734704, 0.94645965, 1.0518653 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36782ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.14292955, 1.54338944, 1.21923745, 0.96647245, 0.78125411,\n",
       "       0.64401644, 0.53842074, 0.45384514, 0.38440982])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e66f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1 -th iteration, Collapsed Time:  7.934950113296509\n",
      "\n",
      "  2 -th iteration, Collapsed Time:  7.2251622676849365\n",
      "\n",
      "  3 -th iteration, Collapsed Time:  6.943118333816528\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "@tf.function\n",
    "def soft_thr(x,alpha):\n",
    "    n = x.shape[0]\n",
    "    S = tf.math.maximum(tf.abs(x)-alpha,0)*tf.math.sign(x)\n",
    "    return S\n",
    "\n",
    "def FISTA(beta, X, y, lamb, L, eta, tol = 1e-08, max_iter = 5000, dtype = tf.float32):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    crit = np.zeros(max_iter)\n",
    "  \n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        dbeta = tf.constant(beta)\n",
    "        dX = tf.constant(X)\n",
    "        dy = tf.constant(y)\n",
    "        t = tf.constant(1.0, dtype=dtype)\n",
    "        dbeta_p = tf.constant(beta)\n",
    "        dbeta_prev = tf.constant(beta)\n",
    "        L_prev = tf.constant(L,dtype=dtype)\n",
    "\n",
    "        for k in range(max_iter):\n",
    "            dymXbp = dy-tf.linalg.matvec(dX,dbeta_p)\n",
    "            drbp = tf.tensordot(dymXbp,dymXbp,axes=1)\n",
    "            dXTrbp = tf.linalg.matvec(dX,dymXbp, \n",
    "                                    transpose_a=True)\n",
    "\n",
    "            i_k = -1\n",
    "            cond = True\n",
    "            while cond:\n",
    "                i_k += 1\n",
    "                L_cur = L_prev*(eta**i_k)\n",
    "                dbstar = dbeta_p + dXTrbp/L_cur\n",
    "                dbeta = soft_thr(dbstar, lamb/L_cur)\n",
    "                diff_beta = dbeta - dbeta_p\n",
    "                RHS_1st = tf.tensordot(diff_beta, \n",
    "                                       diff_beta,axes=1)\n",
    "                RHS_2nd = tf.tensordot(diff_beta, dXTrbp,\n",
    "                                       axes=1)\n",
    "                RHS = L_cur * RHS_1st.numpy() - 2.0 * RHS_2nd.numpy()\n",
    "                dymXb = dy - tf.linalg.matvec(dX,dbeta)\n",
    "                LHS = (tf.tensordot(dymXb,dymXb,\n",
    "                       axes=1)).numpy()-drbp.numpy()\n",
    "                cond = (LHS>RHS)\n",
    "            L_prev = L_cur\n",
    "            tnext =  (1.0+tf.sqrt(1+4*t**2))/2.0\n",
    "            diff_beta = dbeta-dbeta_prev\n",
    "            t1 = (t - 1.0)/tnext\n",
    "            dbeta_p = dbeta+t1*diff_beta\n",
    "            crit[k] = tf.norm(diff_beta) \n",
    "            if crit[k] < tol:\n",
    "                break\n",
    "            t = tnext\n",
    "            dbeta_prev = dbeta\n",
    "    return dbeta.numpy(), crit, k\n",
    "\n",
    "np.random.seed(2022)\n",
    "X = np.random.randn(n,p).astype(np.float32)\n",
    "tr_beta = np.zeros(p).astype(np.float32)\n",
    "tr_beta[:int(0.05*p)] = 1.0\n",
    "y = np.dot(X, tr_beta) + np.random.randn(n).astype(np.float32)\n",
    "\n",
    "for i in np.arange(niter):\n",
    "\n",
    "    beta = np.zeros(p, dtype = np.float32)\n",
    "    lam = np.sqrt(2*np.log(p)/n).astype(np.float32)\n",
    "    L = np.float32(10)\n",
    "    eta = np.float32(2)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    out, crit, step = FISTA(beta, X, y, lam, L, eta, tol = 1e-03, max_iter = 5000)\n",
    "    t2 = time.time()\n",
    "    comp_time_fista[i,4] = t2-t1\n",
    "    \n",
    "    print('\\n ',i+1,'-th iteration, Collapsed Time: ', comp_time_fista[i,4])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858aa83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78795e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./fista_comp_time_n{}_p{}_float.txt'.format(n,p), 'w') as f:\n",
    "    print(('%s\\t '*6 % ('DLL-K','DLL-cuBLAS','PyCUDA','Numba','TF','PyTorch')), end='\\n', file=f)\n",
    "    for i in range(niter):\n",
    "        print(('%.4f\\t '*6 % tuple(comp_time_fista[i])), end='\\n', file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc0d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF20",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
